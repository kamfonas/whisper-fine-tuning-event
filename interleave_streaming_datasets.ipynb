{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c0357",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure datasets is installed from main. Uncomment the following line if you face issues running this script:\n",
    "# !pip install git+https://github.com/huggingface/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794aaced",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Audio, interleave_datasets, IterableDataset, load_dataset, SplitDict\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_streaming_dataset(dataset_name, dataset_config_name, split, **kwargs):\n",
    "    if \"+\" in split:\n",
    "        # load multiple splits separated by the `+` symbol *with* streaming mode\n",
    "        dataset_splits = [load_dataset(dataset_name, dataset_config_name, split=split_name, streaming=True, **kwargs) for split_name in split.split(\"+\")]\n",
    "        # interleave multiple splits to form one dataset\n",
    "        interleaved_dataset = interleave_datasets(dataset_splits)\n",
    "        return interleaved_dataset\n",
    "    else:\n",
    "        # load a single split *with* streaming mode\n",
    "        dataset = load_dataset(dataset_name, dataset_config_name, split=split, streaming=True, **kwargs)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210ca9a-486b-46a2-a675-2526a9bd83f5",
   "metadata": {},
   "source": [
    "### Define the dataset attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07293f-3ba4-4e89-a4ca-8e39409a8373",
   "metadata": {},
   "source": [
    "In this example, we'll show how to combine the Common Voice 11 and FLEURS datasets for Greek (el), parameters for , VoxPopuli, Mulitlingual LibriSpeech are commented out. The resulting training corpus will be equal to the sum of the individual datasets and the test dataset will be equal to the Common Voice 11 test split only. This is particularly beneficial in low-resource settings, where any one of the datasets alone might have insufficient data to train a model.\n",
    "\n",
    "The parameters required are shown below in lists of the same length, with one element per dataset:\n",
    "\n",
    "-   `dataset_names` contains the Hugging Face Hub name of the datasets\n",
    "-   `dataset_config_names` contains the respective language codes.\n",
    "-   `text_column_names` contains the name used for the text feature (column) in each respective dataset\n",
    "-   `train_splits` and `test_splits` contain split names used for each respective dataset. If multiple splits need to be interleaved the names are concatenated into one string separated by the + sign. E.g to merge both test and validation the code should be `\"test+validation\"`. A split name `\"-\"` (dash) can be used to suppress a dataset. This for example is the case if you want the training datasets to contain two datasets and the test come only from the Common Voice 11. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53344f3-c315-430a-a2f3-57aea6bb0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_names = [\"mozilla-foundation/common_voice_11_0\", \"facebook/voxpopuli\", \"facebook/multilingual_librispeech\", \"google/fleurs\"]\n",
    "#dataset_config_names = [\"es\", \"es\", \"spanish\", \"es_419\"]\n",
    "#text_column_names = [\"sentence\", \"normalized_text\", \"text\", \"transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53344f3-c315-430a-a2f3-57aea6bb0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"mozilla-foundation/common_voice_11_0\", \"google/fleurs\"]\n",
    "dataset_config_names = [\"el\", \"el_gr\"]\n",
    "text_column_names = [\"sentence\",  \"transcription\"]\n",
    "train_splits =[\"train+validation\",\"train+validation\"]\n",
    "test_splits  = [\"test\",\"-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215541f6-ee1c-4104-b43c-fa3f7fce0494",
   "metadata": {},
   "source": [
    "### Define the merging function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722a48b-c576-4a63-b2a2-3c264890a75f",
   "metadata": {},
   "source": [
    "We define a function, `load_multiple_streaming_datasets`, that takes as argument a list of datasets, configs, splits (optional) and text column names (optional). It sets them to a specified sampling rate and interleaves them together, giving one merged dataset. This is all \n",
    "done in _streaming mode_: as we iterate over the merged dataset we load samples one-by-one on the fly. No data is\n",
    "saved to disk.\n",
    "\n",
    "We can also specify our strategy for interleaving datasets. The default strategy, `all_exhausted` is an oversampling \n",
    "strategy. In this case, the dataset construction is stopped as soon as every samples in every dataset \n",
    "has been added at least once. In practice, it means that if a dataset is exhausted, it will return to the \n",
    "beginning of this dataset until the stop criterion has been reached. You can specify `stopping_strategy=first_exhausted` \n",
    "for a subsampling strategy, i.e the dataset construction is stopped as soon one of the dataset runs out of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb4cb1-ee27-4270-a474-1bb33e1df65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_streaming_datasets(\n",
    "    dataset_names: List,\n",
    "    dataset_config_names: List,\n",
    "    train_splits: Optional[List] = None,\n",
    "    test_splits: Optional[List] = None,\n",
    "    text_column_names: Optional[List] = None,\n",
    "    sampling_rate: Optional[int] = 16000,\n",
    "    stopping_strategy: Optional[str] = \"all_exhausted\",\n",
    "    **kwargs\n",
    ") -> IterableDataset:\n",
    "\n",
    "    if len(dataset_names) != len(dataset_config_names):\n",
    "        raise ValueError(\n",
    "            f\"Ensure one config is passed for each dataset, got {len(dataset_names)} datasets and\"\n",
    "            f\" {len(dataset_config_names)} configs.\"\n",
    "        )\n",
    "\n",
    "    if train_splits is not None and len(train_splits) != len(dataset_names):\n",
    "        raise ValueError(\n",
    "            f\"Ensure one train_split is passed for each dataset, got {len(dataset_names)} datasets and {len(train_splits)} splits.\"\n",
    "        )\n",
    "\n",
    "    if test_splits is not None and len(test_splits) != len(dataset_names):\n",
    "        raise ValueError(\n",
    "            f\"Ensure one test_split is passed for each dataset, got {len(dataset_names)} datasets and {len(test_splits)} splits.\"\n",
    "        )\n",
    "\n",
    "    if text_column_names is not None and len(text_column_names) != len(dataset_names):\n",
    "        raise ValueError(\n",
    "            f\"Ensure one text column name is passed for each dataset, got {len(dataset_names)} datasets and\"\n",
    "            f\" {len(text_column_names)} text column names.\"\n",
    "        )\n",
    "\n",
    "    train_splits = train_splits if train_splits is not None \\\n",
    "        else [\"train\" for i in range(len(dataset_names))]\n",
    "\n",
    "    test_splits = test_splits if test_splits is not None \\\n",
    "        else [\"test\" for i in range(len(dataset_names))]\n",
    "\n",
    "    text_column_names = (\n",
    "        text_column_names if text_column_names is not None else [\"text\" for i in range(len(dataset_names))]\n",
    "    )\n",
    "\n",
    "\n",
    "    all_datasets = []\n",
    "    all_train_splits = []\n",
    "    all_test_splits  = []\n",
    "    # iterate over the datasets we want to interleave\n",
    "    for dset, cfgNm, trnSplit, tstSplit, colNm in zip(dataset_names,dataset_config_names,train_splits,test_splits,text_column_names):\n",
    "\n",
    "        train_dset_splits = [load_dataset(dset, cfgNm, split=c, streaming=True, **kwargs) for c in trnSplit.split('+') if c != '-']\n",
    "        test_dset_splits  = [load_dataset(dset, cfgNm, split=c, streaming=True, **kwargs) for c in tstSplit.split('+') if c != '-']\n",
    "\n",
    "        train_dset_splits = [ds.cast_column(\"audio\", Audio(sampling_rate)) for ds in train_dset_splits]\n",
    "        test_dset_splits  = [ds.cast_column(\"audio\", Audio(sampling_rate)) for ds in test_dset_splits]\n",
    "\n",
    "        train_dset_splits = [ds.rename_column(colNm, \"text\") for ds in train_dset_splits]\n",
    "        test_dset_splits  = [ds.rename_column(colNm, \"text\") for ds in test_dset_splits]\n",
    "\n",
    "        cols2keep = set([\"audio\", \"text\"])\n",
    "\n",
    "        train_dset_splits = [ds.remove_columns(set(ds.features.keys()) - cols2keep) for ds in train_dset_splits]\n",
    "        test_dset_splits  = [ds.remove_columns(set(ds.features.keys()) - cols2keep) for ds in test_dset_splits]\n",
    "\n",
    "        all_train_splits +=   train_dset_splits\n",
    "        all_test_splits  +=   test_dset_splits\n",
    "\n",
    "\n",
    "    interleaved_train_dataset = interleave_datasets(all_train_splits, stopping_strategy=stopping_strategy)\n",
    "    interleaved_test_dataset = interleave_datasets(all_test_splits, stopping_strategy=stopping_strategy)\n",
    "\n",
    "    return interleaved_train_dataset, interleaved_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539c8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29bc228b-ce9b-4cee-9092-1223ddfa51ad",
   "metadata": {},
   "source": [
    "Let's apply this function to load and merge our four datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae90f83-4ecd-46a3-98be-bd75706e0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = load_multiple_streaming_datasets(dataset_names, \n",
    "        dataset_config_names=dataset_config_names, \n",
    "        train_splits = train_splits,\n",
    "        test_splits = test_splits,\n",
    "        text_column_names=text_column_names, \n",
    "        use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train',train_ds.dataset_size)\n",
    "print('test',train_ds.dataset_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056a693-1fb0-45f4-ad43-be5f1812c1a5",
   "metadata": {},
   "source": [
    "### Iterate over the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe011f-f905-4027-ab67-5c9c3b2b5ac0",
   "metadata": {},
   "source": [
    "We iterate over the dataset, loading and merging samples on the fly. Let's print the transcriptions for the first 10 samples of our merged dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3355a-3c06-4d23-af43-2b93b1ad70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(test_ds):\n",
    "    print(i, sample[\"text\"])\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5ad08-b20e-4cba-a1a9-909fdbf030d4",
   "metadata": {},
   "source": [
    "We can see that the transcriptions take several different formats. Those from Common Voice 11 are cased and punctuated. Those from VoxPopuli are punctuated only. Those from Multilingual LibriSpeech and FLEURS are neither cased not punctuated. We need to normalise the transcriptions to a uniform format before training our model. \n",
    "\n",
    "The following code cell is lifted from the Whisper training notebook: https://github.com/huggingface/community-events/blob/main/whisper-fine-tuning-event/fine-tune-whisper-streaming.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20e9cd-31c2-44cb-872b-333378a92fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "do_lower_case = True\n",
    "do_remove_punctuation = True\n",
    "\n",
    "normalizer = BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d13029-c24f-4a51-aff2-9251a2ceb4ce",
   "metadata": {},
   "source": [
    "Now we define a function to normalise our transcriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e42417-4bd2-46f8-914e-3a6f9f3471ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_transcriptions(batch):\n",
    "    # optional pre-processing steps\n",
    "    transcription = batch[\"sentence\"]\n",
    "    if do_lower_case:\n",
    "        transcription = transcription.lower()\n",
    "    if do_remove_punctuation:\n",
    "        transcription = normalizer(transcription).strip()\n",
    "    batch[\"sentence\"] = transcription\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c67fe-be4b-4ee5-9a1f-0d444f2b5c62",
   "metadata": {},
   "source": [
    "Let's apply the data pre-processing steps to our dataset and view the first 10 samples again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babac71-9157-4d0f-a8a8-184547bdf501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(normalize_transcriptions)\n",
    "\n",
    "for i, sample in enumerate(ds):\n",
    "    print(i, sample[\"sentence\"])\n",
    "    if i == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135627a-a7aa-458c-94b8-57ddeae74a72",
   "metadata": {},
   "source": [
    "This time the transcriptions are in a consistent format. We can use this data to fine-tune our Whisper model. Note that since we've removed punctuation and casing, the Whisper model won't learn to predict these features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('whisper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "56df8cc7a7ee396247f1aaa79087483e047b61a4716ebb1fc601848c69339422"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
